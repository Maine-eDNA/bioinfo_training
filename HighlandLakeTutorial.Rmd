---
title: "Highland Lake Tutorial"
author: "Rene Francolini"
date: "04/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Set Up CyVerse Working Environment

the following lines should be run in the terminal window:
```
cd work/
```
[you should now be in your work/ directory]
```
mkdir fastqc
mkdir raw_reads
mkdir trimmed
mkdir filtered

cp ~/work/data/input/2K_Highland_18S/* raw_reads
```

## Check Data Quality

the following lines should be run in the terminal window:
[you should be in your work/data/output directory]
```
fastqc raw_reads/*fastq.gz
mv raw_reads/*fastqc* fastqc
```

## Cutadapt Command Line

the following lines should be run in the terminal window:
(copies the raw reads to your working directory)
(creates a document with the sample names to loop through)
[start in your work directory]

```
cd raw_reads

ls *_R1_001.fastq.gz | cut -f1 -d "R" > samples
```

the following lines should be run in the terminal at the same time:
(runs cutadapt for all files)
[you should now be in your raw_reads directory]

```
for sample in $(cat samples)
do

echo "On sample: $sample"
    
cutadapt -a ^CYGCGGTAATTCCAGCTC...CRAAGAYGATYAGATACCRT -A ^AYGGTATCTRATCRTCTTYG...GAGCTGGAATTACCGCRG -m 150 -M 550 --discard-untrimmed -o ${sample}R1_001_trimmed.fastq.gz -p ${sample}R2_001_trimmed.fastq.gz ${sample}R1_001.fastq.gz ${sample}R2_001.fastq.gz >> Cutadapt_trimming_stats.txt 2>&1

done

```

the following lines should be run in the terminal window:
(copies the trimmed reads to your trimmed directory)
[you should be in your raw reads directory]

```
mv *trimmed.fastq.gz ../trimmed/

```


## Setting Up R Environment


``` {R environment, message = FALSE}
library(dada2, quietly = TRUE)

packageVersion("dada2")

```


``` {R filenames}
path <- "~/work/trimmed/" #path where the cutadapted files are
list.files(path)

forward_reads <- sort(list.files(path, pattern="_R1_001_trimmed.fastq.gz", full.names = TRUE))

reverse_reads <- sort(list.files(path, pattern="_R2_001_trimmed.fastq.gz", full.names = TRUE))


samples <- sapply(strsplit(basename(forward_reads), "_R"), `[`, 1)

```


## Quality Plot Inspection


```{r plotQuality}
library(ggplot2)
#currently only running the first 4 of the list to save time
plotQualityProfile(forward_reads[1:4])
ggsave(path="~/work/", filename="forward_quality.png")

plotQualityProfile(reverse_reads[1:4])
ggsave(path="~/work/", filename="reverse_quality.png")
```


## Filter and Trimming


```{r filterNames}
filterpath <- "~/work/filtered/" #where our filtered files will live
filtered_reverse_reads <- paste0(filterpath, samples, "_R2_filtered.fq.gz")
filtered_forward_reads <- paste0(filterpath, samples, "_R1_filtered.fq.gz")
```

```{r filterAndTrim}
filtered_out <- filterAndTrim(forward_reads, 
                              filtered_forward_reads,
                              reverse_reads, 
                              filtered_reverse_reads, 
                              maxEE=c(2,2),
                              minLen=175, 
                              truncLen=c(250,200))
```

```{r ViewFiltered}
filtered_out
```

```{r plotQualityFiltered}
plotQualityProfile(filtered_forward_reads[1:4])
ggsave(path="~/work/", filename="forward_filtered_quality.png")

plotQualityProfile(filtered_reverse_reads[1:4])
ggsave(path="~/work/", filename="reverse_filtered_quality.png")
```


## Generate Error Model


```{r errorModel}
err_forward_reads <- learnErrors(filtered_forward_reads)
err_reverse_reads <- learnErrors(filtered_reverse_reads)

#set multithread = TRUE if running on your own system:
#err_forward_reads <- learnErrors(filtered_forward_reads, multithread = TRUE)
#err_reverse_reads <- learnErrors(filtered_reverse_reads, multithread = TRUE)
```

```{r plotErrors}
plotErrors(err_forward_reads, nominalQ=TRUE)
ggsave(path="~/work/", filename="forward_errors.png")

plotErrors(err_reverse_reads, nominalQ=TRUE)
ggsave(path="~/work/", filename="reverse_errors.png")
```

## Dereplication

```{r dereplication}
derep_forward <- derepFastq(filtered_forward_reads, verbose=TRUE)
names(derep_forward) <- samples 
derep_reverse <- derepFastq(filtered_reverse_reads, verbose=TRUE)
names(derep_reverse) <- samples
```

# Inferring ASVs

```{r inferASV}
#dada_forward <- dada(derep_forward, err=err_forward_reads, #pool="pseudo")
#dada_reverse <- dada(derep_reverse, err=err_reverse_reads, #pool="pseudo")

#set multithread = TRUE if running on your own system:
dada_forward <- dada(derep_forward, err=err_forward_reads, pool="pseudo", multithread = TRUE)
dada_reverse <- dada(derep_reverse, err=err_reverse_reads, pool="pseudo", multithread = TRUE)
```


## Merging paired reads

```{r merge}
merged_amplicons <- mergePairs(dada_forward, 
                              derep_forward, 
                              dada_reverse,
                              derep_reverse, 
                              minOverlap=20)
```


## Count Table and Summary

```{r seqtab}
seqtab <- makeSequenceTable(merged_amplicons)
dim(seqtab)
View(seqtab)
```

```{r removeChimeras}
seqtab.nochim <- removeBimeraDenovo(seqtab, multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
View(seqtab.nochim)

sum(seqtab.nochim)/sum(seqtab)

write.csv(seqtab.nochim, "~/work/seqtab-nochim.csv")
```

```{r readCounts}
getN <- function(x) sum(getUniques(x))


summary_tab <- data.frame(row.names=samples, dada2_input=filtered_out[,1],
               filtered=filtered_out[,2], dada_f=sapply(dada_forward, getN),
               dada_r=sapply(dada_reverse, getN), merged=sapply(merged_amplicons, getN),
               nonchim=rowSums(seqtab.nochim),
               final_perc_reads_retained=round(rowSums(seqtab.nochim)/filtered_out[,1]*100, 1))

View(summary_tab)

write.table(summary_tab, "~/work/read-count-tracking.tsv", quote=FALSE, sep="\t", col.names=NA)

```


## ASV Tables

``` {R ASVFastaFile}
asv_seqs <- colnames(seqtab.nochim)
asv_headers <- vector(dim(seqtab.nochim)[2], mode="character")

for (i in 1:dim(seqtab.nochim)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep="_")
}

asv_fasta <- c(rbind(asv_headers, asv_seqs))

write(asv_fasta, "~/work/ASVs.fa")
#click on ASVs.fa to view file in R Environment
```

``` {R CountTable}
asv_tab <- t(seqtab.nochim)
row.names(asv_tab) <- sub(">", "", asv_headers)

View(asv_tab)

write.table(asv_tab, "~/work/ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)
```


## Assign Taxonomy


``` {R Assign Taxonomy}
taxa <- assignTaxonomy(seqtab.nochim, "~/work/data/input/raw_reads/pr2_version_4.14.0_SSU_dada2.fasta.gz", multithread=T, minBoot=50)

rownames(taxa) <- gsub(pattern=">", replacement="", x=asv_headers)

write.csv(taxa, "~/work/ASV_taxa.csv")
```


## Phun with Phyloseq

``` {R PhyloseqObj}

library(phyloseq)
library(ggplot2)

info <- read.table("~/work/data/input/raw_reads/info_18S.txt", header=T,sep="\t")
rownames(info) <- rownames(seqtab.nochim)

rawasvs <- phyloseq(otu_table(asv_tab, taxa_are_rows=T), 
                    sample_data(info), 
                    tax_table(as.matrix(taxa)))

rawasvs@sam_data
nsamples(rawasvs)
head(rawasvs@otu_table)
head(rawasvs@tax_table)


wh0 <-  genefilter_sample(rawasvs, filterfun_sample(function(x) x > 2), A=2)
ps <- prune_taxa(wh0, rawasvs)

```


``` {R BarPlotTop20}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:200]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
#ps.top20@sam_data

p <- plot_bar(ps.top20, x="JulDay", fill="Phylum") +
  theme(text = element_text(size = 14) , legend.position = "right") +
  scale_x_continuous(breaks=c(186,192,195,199,205,212,219,227,233,241,255,268,285))+
  facet_wrap(~Layer)
p
ggsave(p, path="~/work/", filename="abundance.png")
```

``` {R ordinationPlots}
library(vegan)

ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")

plot_ordination(ps.prop, ord.nmds.bray, color="Layer",shape="Month_char", title="Bray NMDS")+
  geom_point(size = 7)
ggsave(path="~/work/", filename="bray_NMDS_layer.png")

plot_ordination(ps.prop, ord.nmds.bray, color="Temp",shape="Month_char", title="Bray NMDS")+
  geom_point(size = 7)
ggsave(path="~/work/", filename="bray_NMDS_temp.png")
```

``` {R RichnessPlot}
plot_richness(ps, x="Sample.ID",measures=c("Observed", "Shannon", "Chao1"),
              color="Layer", shape="Month_char") 
ggsave(path="~/work/", filename="richness.png")
```

## Copying data to be Saved

the following lines should be run in the terminal window:
```
cp -r ~/work/* ~/work/data/output/
```

